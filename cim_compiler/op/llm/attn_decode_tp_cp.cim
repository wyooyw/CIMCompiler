{% include 'op/llm/attn_decode_utils.cim' %}
{% include 'op/llm/special_regs.cim' %}


{% if seqlen % cp_group.world_size != 0 %}
    {% set error_msg = "seqlen must be divisible by cp_group.world_size" %}
    {{ raise(error_msg) }}
{% endif %}

def get_next_rank(rank<index>, world_size<index>){
    return (rank + 1) % world_size;
}

def get_prev_rank(rank<index>, world_size<index>){
    return (rank - 1 + world_size) % world_size;
}

def get_row_to_send(rank<index>, step<index>, world_size<index>){
    return (rank - step + world_size) % world_size;
}

def get_row_to_recv(rank<index>, step<index>, world_size<index>){
    return (rank - step - 1 + world_size) % world_size;
}

def send(rank<index>, step<index>, world_size<index>, data< <-1, -1>, fp16, __OUTPUT_MEMORY__>){
    rank_to_send = get_next_rank(rank, world_size);
    data_to_send = data[get_row_to_send(rank, step, world_size), :];
    
    fake_data_to_recv = data[get_row_to_recv(rank_to_send, step, world_size), :];
    Send(data_to_send, fake_data_to_recv, rank_to_send, step);
}

def recv(rank<index>, step<index>, world_size<index>, data< <-1, -1>, fp16, __OUTPUT_MEMORY__>){
    rank_to_recv = get_prev_rank(rank, world_size);
    data_to_recv = data[get_row_to_recv(rank, step, world_size), :];

    fake_data_to_send = data[get_row_to_send(rank_to_recv, step, world_size), :];
    Recv(fake_data_to_send, data_to_recv, rank_to_recv, step);
}

def all_gather(
    data< <{{world_size}}, -1>, fp16, __OUTPUT_MEMORY__>
    ){
    rank = {{core_id}};
    world_size = {{world_size}};
    
    step_max = world_size - 1;
    for step in range(0, step_max) carry (){
        {% if core_id % 2 == 0 %}
            send(rank, step, world_size, data);
            recv(rank, step, world_size, data);
        {% else %}
            recv(rank, step, world_size, data);
            send(rank, step, world_size, data);
        {% endif %}
    };
}

def cp_online_softmax(
    x< <-1>, fp16, __OUTPUT_MEMORY__>,
    score< <-1>, fp16, __OUTPUT_MEMORY__>
    ) {
    // local softmax
    max_x = Buffer(<1>, fp16, __OUTPUT_MEMORY__);
    SIMD(REDUCE_MAX, x, max_x);
    SIMD(VS_SUB, x, max_x, x);
    SIMD(V_EXP, x, x);

    sum_exp_x = Buffer(<1>, fp16, __OUTPUT_MEMORY__);
    SIMD(REDUCE_SUM, x, sum_exp_x);
    SIMD(VS_DIV, x, sum_exp_x, score);

    // all-gather sum_exp_x and max_x
    all_sum_exp_x = Buffer(<{{world_size}}, 1>, fp16, __OUTPUT_MEMORY__);
    all_max_x = Buffer(<{{world_size}}, 1>, fp16, __OUTPUT_MEMORY__);
    Trans(sum_exp_x, all_sum_exp_x[{{core_id}}, 0]);
    all_gather(all_denominator);
    Trans(max_x, all_max_x[{{core_id}}, 0]);
    all_gather(all_max_x);

    total_max_x = Buffer(<1>, fp16, __OUTPUT_MEMORY__);
    SIMD(REDUCE_MAX, all_max_x, total_max_x);

    all_max_x_sub_total_max_x = Buffer(<{{world_size}}, 1>, fp16, __OUTPUT_MEMORY__);
    SIMD(VS_SUB, all_max_x, total_max_x, all_max_x_sub_total_max_x);
    factors = Buffer(<{{world_size}}, 1>, fp16, __OUTPUT_MEMORY__);
    SIMD(V_EXP, all_max_x_sub_total_max_x, factors);

    SIMD(VVMUL, factors, all_sum_exp_x, all_sum_exp_x);
    final_denominator = Buffer(<1>, fp16, __OUTPUT_MEMORY__);
    SIMD(REDUCE_SUM, all_sum_exp_x, final_denominator);

    final_factor = Buffer(<1>, fp16, __OUTPUT_MEMORY__);
    SIMD(VS_DIV, all_sum_exp_x[{{core_id}}, 0], final_denominator, final_factor);
    SIMD(VSMUL, score, final_factor, score);
}

def main(){
    set_special_regs();

    global_pimset_mask = Buffer(<{{N_GROUP_VCOL}}>, int1, __GLOBAL__);
    local_pimset_mask = Buffer(<{{N_GROUP_VCOL}}>, int1, __INPUT_MEMORY__);
    Trans(global_pimset_mask, local_pimset_mask);
    CIMSet(local_pimset_mask);
    
    q_global = Buffer(<{{head_hidden}}>, fp16, __GLOBAL__);
    k_global = Buffer(<{{seqlen // cp_group.world_size}}, {{head_hidden}}>, fp16, __GLOBAL__);
    v_global = Buffer(<{{seqlen // cp_group.world_size}}, {{head_hidden}}>, fp16, __GLOBAL__);
    output_global = Buffer(<{{head_hidden // cp_group.world_size}}>, fp16, __GLOBAL__);
    
    macros = Buffer(<{{N_ROW}}, {{N_COMP}}, 1, {{N_GROUP_VCOL}}>, fp16, __MACRO__);
    pim_input_reg_buffer = Buffer(<{{N_COMP}}>, fp16, __PIM_INPUT_REG_BUFFER__);
    pim_output_reg_buffer = Buffer(<{{N_GROUP_VCOL}}>, fp16, __PIM_OUTPUT_REG_BUFFER__);

    // step 0: load q into local
    q_local = Buffer(<{{head_hidden}}>, fp16, __OUTPUT_MEMORY__);
    Trans(q_global, q_local);

    // step 1: load all kv caches into macro
    k_row_begin = 0;
    k_row_size = {{ (head_hidden // N_COMP) * ((seqlen // cp_group.world_size) // N_GROUP_VCOL) }};
    k_row_end = k_row_begin + k_row_size;
    k_macro = macros[k_row_begin:k_row_end, 0:{{N_COMP}}, 0:1, 0:{{N_GROUP_VCOL}}];

    v_row_begin = k_row_end;
    v_row_size = {{ ((seqlen // cp_group.world_size) // N_COMP) * (head_hidden // N_GROUP_VCOL) }};
    v_row_end = v_row_begin + v_row_size;
    v_macro = macros[v_row_begin:v_row_end, 0:{{N_COMP}}, 0:1, 0:{{N_GROUP_VCOL}}];
    
    transpose_unit = Buffer(<2, {{transpose_row * transpose_col}}>, fp16, __TRANSPOSE_MEMORY__);
    load_transpose_into_macro(k_global, k_macro, transpose_unit);
    load_into_macro(v_global, v_macro);

    // step 2: compute qK^T
    attn_out1 = Buffer(<{{seqlen // cp_group.world_size}}>, fp16, __OUTPUT_MEMORY__);
    gemv(q_local, k_macro, attn_out1, {{ head_hidden // N_COMP }}, pim_input_reg_buffer, pim_output_reg_buffer);

    // step 3: online softmax
    score = Buffer(<{{seqlen // cp_group.world_size}}>, fp16, __OUTPUT_MEMORY__);
    cp_online_softmax(attn_out1, score);

    // step 4: compute softmax(qK^T)V
    attn_out2= Buffer(<{{head_hidden}}>, fp16, __OUTPUT_MEMORY__);
    gemv(score, v_macro, attn_out2, {{ (seqlen // cp_group.world_size) // N_COMP }}, pim_input_reg_buffer, pim_output_reg_buffer);

    // step 5 reduce-scatter
    attn_out3 = Buffer(<{{head_hidden // cp_group.world_size}}>, fp16, __OUTPUT_MEMORY__);
    reduce_scatter(attn_out2, attn_out3);
    
    // step 6
    Trans(attn_out3, output_global);
}
